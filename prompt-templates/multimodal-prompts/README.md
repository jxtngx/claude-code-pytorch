# Multimodal Prompts

## Templates

<table>
<thead>
<tr>
<th>Template</th>
<th>Description</th>
<th>Key Features</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="vision-language-understanding.md">Vision-Language Understanding</a></td>
<td>Build models that understand both images and text</td>
<td>CLIP/BLIP, Zero-shot >70%, Contrastive learning</td>
</tr>
<tr>
<td><a href="image-captioning.md">Image Captioning</a></td>
<td>Generate descriptive captions for images</td>
<td>BLEU-4 >0.35, Beam search, Web interface</td>
</tr>
<tr>
<td><a href="visual-question-answering.md">Visual Question Answering</a></td>
<td>Answer questions about images</td>
<td>ViT+LM, VQA-v2 >65%, Attention maps</td>
</tr>
<tr>
<td><a href="audio-visual-speech-recognition.md">Audio-Visual Speech Recognition</a></td>
<td>Transcribe speech using audio and visual cues</td>
<td>Conformer/Wav2Vec2, WER <10%, Lip reading</td>
</tr>
<tr>
<td><a href="document-understanding.md">Document Understanding</a></td>
<td>Extract structured information from scanned documents</td>
<td>OCR integration, Layout-aware, Table extraction</td>
</tr>
</tbody>
</table>